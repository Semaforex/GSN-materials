{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Points: 20\n",
    "\n",
    "You will be working with RGBNet: a network that accepts pixel position as input and outputs a triplet with R, G, B channels of that pixels.\n",
    "RGBNet is trained on a fixed image. Your tasks are:\n",
    "\n",
    "1. (14 points) Fill gaps in the code, which creates embeddings in 2 ways:\n",
    "    - Learned embedding of size 64 (7 points)\n",
    "    - Positional embedding of size 64 (7 points)\n",
    "\n",
    "\n",
    "Please note that your code should train within 1 minute and report training loss below 15 for each case.\n",
    "2. (6 points) Visualize output of the network for each encoding. Does it resemble the input image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import urllib\n",
    "from typing import Literal\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "IMG_URL = \"https://i.natgeofe.com/k/8fa25ea4-6409-47fb-b3cc-4af8e0dc9616/red-eyed-tree-frog-on-leaves-3-2.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url_response = urllib.request.urlopen(IMG_URL)\n",
    "img = cv2.imdecode(np.array(bytearray(url_response.read()), dtype=np.uint8), -1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = cv2.resize(img, (0,0), fx=0.01, fy=0.01) \n",
    "im_h, im_w = img.shape[0], img.shape[1]\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveEncoding(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 64)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.linear(x.float())\n",
    "        return self.linear(x.float())\n",
    "\n",
    "\n",
    "class LearnedEncoding(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        # Your code goes here. Output dim of embedding should be 64 \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=100, embedding_dim=32)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Your code goes here. Output dim of embedding should be 64 \n",
    "        x_coord = x[:, 0]\n",
    "        y_coord = x[:, 1]\n",
    "        emb_x = self.embedding(x_coord)\n",
    "        emb_y = self.embedding(y_coord)\n",
    "        return torch.cat([emb_x, emb_y], dim=1)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):    \n",
    "    def __init__(self) -> None:\n",
    "        # Your code goes here. Output dim of embedding should be 64 \n",
    "        super().__init__()\n",
    "        self.num_frequencies = 64 // 4\n",
    "        self.frequencies = torch.pow(2, torch.arange(self.num_frequencies)).float()\n",
    "        self.register_buffer('freq_bands', self.frequencies)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Your code goes here. Output dim of embedding should be 64 \n",
    "\n",
    "        x_norm = x.float()/20\n",
    "\n",
    "        x_proj = x_norm.float().unsqueeze(-1)*self.freq_bands*math.pi\n",
    "        sin_embed = torch.sin(x_proj)\n",
    "        cos_embed = torch.cos(x_proj)\n",
    "\n",
    "        embeddings = torch.cat([sin_embed, cos_embed], dim=1)\n",
    "        return embeddings.reshape(-1, 64).reshape((x.shape[0], -1))\n",
    "\n",
    "\n",
    "# Define the network\n",
    "class RGBNet(nn.Module):\n",
    "    def __init__(self, encoding_type: Literal[\"naive\", \"learned\", \"positional\"]) -> None:\n",
    "        super().__init__()\n",
    "        if encoding_type == \"naive\":\n",
    "            self.encoding = NaiveEncoding()\n",
    "        elif encoding_type == \"learned\":\n",
    "            self.encoding = LearnedEncoding() \n",
    "        elif encoding_type == \"positional\":\n",
    "            self.encoding = PositionalEncoding()\n",
    "        else:\n",
    "            raise ValueError(\"Wrong encoding type!\")\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 3)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.encoding(x)\n",
    "        x = F.softplus(self.fc1(x))\n",
    "        x = F.softplus(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(used_embedding: Literal[\"naive\", \"learned\", \"positional\"]) -> torch.nn.Module:\n",
    "    # Instantiate the model and set it to the GPU (if available)\n",
    "    model = RGBNet(encoding_type=used_embedding)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss(reduction=\"mean\")\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Define the number of epochs and batch size\n",
    "    num_epochs = 300\n",
    "    batch_size = 32\n",
    "\n",
    "    X, y = torch.cartesian_prod(torch.tensor(range(im_w)), torch.tensor(range(im_h))).to(device), torch.flatten(torch.tensor(img, dtype=torch.float32), start_dim=0, end_dim=1).to(device)\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        perm = torch.randperm(X.size(0))\n",
    "        X, y = X[perm,:], y[perm, :]\n",
    "        for i in range(0, X.shape[0], batch_size):\n",
    "            # Get the current batch\n",
    "            X_batch = X[i:i+batch_size]\n",
    "            y_batch = y[i:i+batch_size]\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/X.size(0)}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_output(model: RGBNet) -> None:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    X = torch.cartesian_prod(torch.tensor(range(im_w)), torch.tensor(range(im_h))).to(device)\n",
    "    model.eval()\n",
    "    with(torch.no_grad()):\n",
    "        output = model(X).reshape(im_h, im_w, 3)\n",
    "    \n",
    "    print(output.shape)\n",
    "    \n",
    "    img = output.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 122.63380818872407\n",
      "Epoch [2/300], Loss: 62.706803422919066\n",
      "Epoch [3/300], Loss: 60.09269816315119\n",
      "Epoch [4/300], Loss: 62.943896034346196\n",
      "Epoch [5/300], Loss: 60.53789952713224\n",
      "Epoch [6/300], Loss: 62.50190545007381\n",
      "Epoch [7/300], Loss: 58.6876462593606\n",
      "Epoch [8/300], Loss: 59.8224369172127\n",
      "Epoch [9/300], Loss: 58.886397401308685\n",
      "Epoch [10/300], Loss: 60.077960880121324\n",
      "Epoch [11/300], Loss: 56.97178080334641\n",
      "Epoch [12/300], Loss: 54.598853326612904\n",
      "Epoch [13/300], Loss: 52.462361419255835\n",
      "Epoch [14/300], Loss: 54.05530298470352\n",
      "Epoch [15/300], Loss: 53.08645573629212\n",
      "Epoch [16/300], Loss: 55.020208051127774\n",
      "Epoch [17/300], Loss: 57.59826906265751\n",
      "Epoch [18/300], Loss: 50.68257387222782\n",
      "Epoch [19/300], Loss: 49.85767586000504\n",
      "Epoch [20/300], Loss: 49.75793189826649\n",
      "Epoch [21/300], Loss: 48.36961962440596\n",
      "Epoch [22/300], Loss: 49.20083463466662\n",
      "Epoch [23/300], Loss: 46.3387709938436\n",
      "Epoch [24/300], Loss: 44.91529501638105\n",
      "Epoch [25/300], Loss: 44.14581755888627\n",
      "Epoch [26/300], Loss: 42.41619226130472\n",
      "Epoch [27/300], Loss: 41.09700926328035\n",
      "Epoch [28/300], Loss: 42.3824467109645\n",
      "Epoch [29/300], Loss: 41.095255346342164\n",
      "Epoch [30/300], Loss: 39.90053414199759\n",
      "Epoch [31/300], Loss: 42.52943982946159\n",
      "Epoch [32/300], Loss: 41.83188738141741\n",
      "Epoch [33/300], Loss: 39.093816519882274\n",
      "Epoch [34/300], Loss: 38.28286996305263\n",
      "Epoch [35/300], Loss: 35.860389533680156\n",
      "Epoch [36/300], Loss: 36.2878407069615\n",
      "Epoch [37/300], Loss: 34.00589179113713\n",
      "Epoch [38/300], Loss: 35.56238791470154\n",
      "Epoch [39/300], Loss: 37.873199462890625\n",
      "Epoch [40/300], Loss: 36.13634923416349\n",
      "Epoch [41/300], Loss: 32.982628255395845\n",
      "Epoch [42/300], Loss: 32.18059515183972\n",
      "Epoch [43/300], Loss: 30.454689271988407\n",
      "Epoch [44/300], Loss: 30.096719733031662\n",
      "Epoch [45/300], Loss: 31.42808588968444\n",
      "Epoch [46/300], Loss: 29.39735859110608\n",
      "Epoch [47/300], Loss: 28.035120493805355\n",
      "Epoch [48/300], Loss: 27.94524921469974\n",
      "Epoch [49/300], Loss: 27.959593953075498\n",
      "Epoch [50/300], Loss: 26.182032431325606\n",
      "Epoch [51/300], Loss: 25.28719030986733\n",
      "Epoch [52/300], Loss: 24.2107909945299\n",
      "Epoch [53/300], Loss: 25.34353813487813\n",
      "Epoch [54/300], Loss: 23.798716707713044\n",
      "Epoch [55/300], Loss: 21.865380282775597\n",
      "Epoch [56/300], Loss: 22.91793408371886\n",
      "Epoch [57/300], Loss: 21.50558123610536\n",
      "Epoch [58/300], Loss: 21.814389312322238\n",
      "Epoch [59/300], Loss: 23.192719033236877\n",
      "Epoch [60/300], Loss: 25.929411927675872\n",
      "Epoch [61/300], Loss: 21.319005904659146\n",
      "Epoch [62/300], Loss: 19.778368268694198\n",
      "Epoch [63/300], Loss: 19.142453101373487\n",
      "Epoch [64/300], Loss: 17.59002729495\n",
      "Epoch [65/300], Loss: 18.21171176049017\n",
      "Epoch [66/300], Loss: 17.128869333574848\n",
      "Epoch [67/300], Loss: 16.318715161442206\n",
      "Epoch [68/300], Loss: 17.26294673093453\n",
      "Epoch [69/300], Loss: 17.128633806782386\n",
      "Epoch [70/300], Loss: 16.214651977960965\n",
      "Epoch [71/300], Loss: 18.31456823392947\n",
      "Epoch [72/300], Loss: 15.334765702348701\n",
      "Epoch [73/300], Loss: 13.807438406526767\n",
      "Epoch [74/300], Loss: 13.972703010805192\n",
      "Epoch [75/300], Loss: 12.51473380233835\n",
      "Epoch [76/300], Loss: 11.759418733658329\n",
      "Epoch [77/300], Loss: 11.897326280444448\n",
      "Epoch [78/300], Loss: 12.451553960000314\n",
      "Epoch [79/300], Loss: 14.974519720824633\n",
      "Epoch [80/300], Loss: 13.242149247551843\n",
      "Epoch [81/300], Loss: 10.960824148995536\n",
      "Epoch [82/300], Loss: 10.27211439774333\n",
      "Epoch [83/300], Loss: 10.110191187001593\n",
      "Epoch [84/300], Loss: 10.379513120870985\n",
      "Epoch [85/300], Loss: 10.31817619921425\n",
      "Epoch [86/300], Loss: 10.156104865711406\n",
      "Epoch [87/300], Loss: 9.874212818761025\n",
      "Epoch [88/300], Loss: 9.620489568754275\n",
      "Epoch [89/300], Loss: 9.743296434253041\n",
      "Epoch [90/300], Loss: 9.308924081688103\n",
      "Epoch [91/300], Loss: 10.787766645580943\n",
      "Epoch [92/300], Loss: 8.493469994189002\n",
      "Epoch [93/300], Loss: 8.435809508996076\n",
      "Epoch [94/300], Loss: 8.341529564923405\n",
      "Epoch [95/300], Loss: 8.316955337876\n",
      "Epoch [96/300], Loss: 7.2554847787602155\n",
      "Epoch [97/300], Loss: 6.612723680135841\n",
      "Epoch [98/300], Loss: 6.323331384614866\n",
      "Epoch [99/300], Loss: 7.228928324264316\n",
      "Epoch [100/300], Loss: 6.573499582879554\n",
      "Epoch [101/300], Loss: 6.645210811070034\n",
      "Epoch [102/300], Loss: 8.457377473330169\n",
      "Epoch [103/300], Loss: 6.439746716055453\n",
      "Epoch [104/300], Loss: 5.225763839510729\n",
      "Epoch [105/300], Loss: 4.98887205343642\n",
      "Epoch [106/300], Loss: 5.06524300465386\n",
      "Epoch [107/300], Loss: 5.600956301535329\n",
      "Epoch [108/300], Loss: 4.994489520376179\n",
      "Epoch [109/300], Loss: 5.1624934640348235\n",
      "Epoch [110/300], Loss: 4.7183217826526835\n",
      "Epoch [111/300], Loss: 4.455006893878708\n",
      "Epoch [112/300], Loss: 4.287138275287118\n",
      "Epoch [113/300], Loss: 4.226083838994602\n",
      "Epoch [114/300], Loss: 3.991294693836968\n",
      "Epoch [115/300], Loss: 3.912164556265976\n",
      "Epoch [116/300], Loss: 3.7989648695914977\n",
      "Epoch [117/300], Loss: 4.184368036859047\n",
      "Epoch [118/300], Loss: 4.037876621369393\n",
      "Epoch [119/300], Loss: 3.712449289137317\n",
      "Epoch [120/300], Loss: 3.309127543928436\n",
      "Epoch [121/300], Loss: 3.417408015870828\n",
      "Epoch [122/300], Loss: 3.4948427841960013\n",
      "Epoch [123/300], Loss: 3.474685932634064\n",
      "Epoch [124/300], Loss: 3.540327472071494\n",
      "Epoch [125/300], Loss: 3.581778385672152\n",
      "Epoch [126/300], Loss: 4.416128044304211\n",
      "Epoch [127/300], Loss: 4.177915863177743\n",
      "Epoch [128/300], Loss: 4.885882320491949\n",
      "Epoch [129/300], Loss: 5.044292133524671\n",
      "Epoch [130/300], Loss: 5.117902861212805\n",
      "Epoch [131/300], Loss: 4.479480361059514\n",
      "Epoch [132/300], Loss: 4.129889642038653\n",
      "Epoch [133/300], Loss: 3.3171068446427445\n",
      "Epoch [134/300], Loss: 2.8404684945734964\n",
      "Epoch [135/300], Loss: 2.7955000653244935\n",
      "Epoch [136/300], Loss: 3.0151651092388665\n",
      "Epoch [137/300], Loss: 2.7498854909624373\n",
      "Epoch [138/300], Loss: 2.3910052655479324\n",
      "Epoch [139/300], Loss: 2.555084074697187\n",
      "Epoch [140/300], Loss: 2.247468302326818\n",
      "Epoch [141/300], Loss: 2.6585687953755603\n",
      "Epoch [142/300], Loss: 2.550954251794771\n",
      "Epoch [143/300], Loss: 2.8235107281241\n",
      "Epoch [144/300], Loss: 3.334197083925871\n",
      "Epoch [145/300], Loss: 2.9346571847590432\n",
      "Epoch [146/300], Loss: 3.2795406991984986\n",
      "Epoch [147/300], Loss: 3.388127102829894\n",
      "Epoch [148/300], Loss: 4.461128700713408\n",
      "Epoch [149/300], Loss: 3.534918007213399\n",
      "Epoch [150/300], Loss: 2.7462321734098794\n",
      "Epoch [151/300], Loss: 2.2955287151072983\n",
      "Epoch [152/300], Loss: 2.092237942779119\n",
      "Epoch [153/300], Loss: 2.016375620793637\n",
      "Epoch [154/300], Loss: 2.0251523162912113\n",
      "Epoch [155/300], Loss: 1.942298489232217\n",
      "Epoch [156/300], Loss: 1.9470364091583112\n",
      "Epoch [157/300], Loss: 1.844421896517002\n",
      "Epoch [158/300], Loss: 2.563219364887009\n",
      "Epoch [159/300], Loss: 2.578963398384059\n",
      "Epoch [160/300], Loss: 2.1492121604181107\n",
      "Epoch [161/300], Loss: 2.5792510520478\n",
      "Epoch [162/300], Loss: 2.730123269393147\n",
      "Epoch [163/300], Loss: 2.862149673672865\n",
      "Epoch [164/300], Loss: 2.844364500265517\n",
      "Epoch [165/300], Loss: 3.929130316879343\n",
      "Epoch [166/300], Loss: 4.639917197864726\n",
      "Epoch [167/300], Loss: 4.982301386820007\n",
      "Epoch [168/300], Loss: 4.313926595696656\n",
      "Epoch [169/300], Loss: 3.527200378031225\n",
      "Epoch [170/300], Loss: 3.0101367185742074\n",
      "Epoch [171/300], Loss: 3.120466227904992\n",
      "Epoch [172/300], Loss: 2.3533533773114605\n",
      "Epoch [173/300], Loss: 5.233376111852409\n",
      "Epoch [174/300], Loss: 3.877290941053821\n",
      "Epoch [175/300], Loss: 3.5058591288904988\n",
      "Epoch [176/300], Loss: 2.8464246916880804\n",
      "Epoch [177/300], Loss: 2.4187878859207927\n",
      "Epoch [178/300], Loss: 2.6577986264558433\n",
      "Epoch [179/300], Loss: 2.2168564554733066\n",
      "Epoch [180/300], Loss: 1.7276600165301204\n",
      "Epoch [181/300], Loss: 2.1025655939831713\n",
      "Epoch [182/300], Loss: 2.94523434265418\n",
      "Epoch [183/300], Loss: 2.362728659458424\n",
      "Epoch [184/300], Loss: 1.6098387010635868\n",
      "Epoch [185/300], Loss: 2.210703109266571\n",
      "Epoch [186/300], Loss: 1.7811293140534432\n",
      "Epoch [187/300], Loss: 2.047667608832434\n",
      "Epoch [188/300], Loss: 2.0592037082267796\n",
      "Epoch [189/300], Loss: 1.9196658508019513\n",
      "Epoch [190/300], Loss: 1.678713271145447\n",
      "Epoch [191/300], Loss: 2.401567212996944\n",
      "Epoch [192/300], Loss: 2.164805746298232\n",
      "Epoch [193/300], Loss: 1.8731862081360706\n",
      "Epoch [194/300], Loss: 2.4977965772426622\n",
      "Epoch [195/300], Loss: 2.620625517884707\n",
      "Epoch [196/300], Loss: 4.17056818052371\n",
      "Epoch [197/300], Loss: 4.313077627788491\n",
      "Epoch [198/300], Loss: 2.6256802554504115\n",
      "Epoch [199/300], Loss: 2.9820927672671833\n",
      "Epoch [200/300], Loss: 1.9250170228668073\n",
      "Epoch [201/300], Loss: 1.582896219420543\n",
      "Epoch [202/300], Loss: 1.4031062895251858\n",
      "Epoch [203/300], Loss: 1.7321151720214\n",
      "Epoch [204/300], Loss: 1.460922755404002\n",
      "Epoch [205/300], Loss: 1.046707403824626\n",
      "Epoch [206/300], Loss: 1.2001215257952291\n",
      "Epoch [207/300], Loss: 1.99148928734564\n",
      "Epoch [208/300], Loss: 3.009218971850136\n",
      "Epoch [209/300], Loss: 2.793506358625702\n",
      "Epoch [210/300], Loss: 2.307810304351666\n",
      "Epoch [211/300], Loss: 1.9263789708713233\n",
      "Epoch [212/300], Loss: 1.8237256036925427\n",
      "Epoch [213/300], Loss: 1.7356020712083386\n",
      "Epoch [214/300], Loss: 1.6505506005704678\n",
      "Epoch [215/300], Loss: 1.39826249746683\n",
      "Epoch [216/300], Loss: 1.1984516244879515\n",
      "Epoch [217/300], Loss: 0.9385191965762372\n",
      "Epoch [218/300], Loss: 0.7954514718824818\n",
      "Epoch [219/300], Loss: 1.2328583875559442\n",
      "Epoch [220/300], Loss: 1.2114229290166758\n",
      "Epoch [221/300], Loss: 1.3098017279453542\n",
      "Epoch [222/300], Loss: 1.4293131916204356\n",
      "Epoch [223/300], Loss: 1.4031708361366377\n",
      "Epoch [224/300], Loss: 1.6270479496722947\n",
      "Epoch [225/300], Loss: 1.7979070008625084\n",
      "Epoch [226/300], Loss: 1.6267160358516852\n",
      "Epoch [227/300], Loss: 1.5248311961301462\n",
      "Epoch [228/300], Loss: 2.083501464210897\n",
      "Epoch [229/300], Loss: 1.9190648909538024\n",
      "Epoch [230/300], Loss: 1.4112904456353956\n",
      "Epoch [231/300], Loss: 1.2631723496221727\n",
      "Epoch [232/300], Loss: 1.0475679344845257\n",
      "Epoch [233/300], Loss: 1.240823347997006\n",
      "Epoch [234/300], Loss: 1.3899084499904089\n",
      "Epoch [235/300], Loss: 1.376957119884579\n",
      "Epoch [236/300], Loss: 1.893187957974623\n",
      "Epoch [237/300], Loss: 2.30236997912007\n",
      "Epoch [238/300], Loss: 2.192911484274447\n",
      "Epoch [239/300], Loss: 2.2290112104284048\n",
      "Epoch [240/300], Loss: 1.9046439904771093\n",
      "Epoch [241/300], Loss: 2.1254553421301776\n",
      "Epoch [242/300], Loss: 2.0143987462267896\n",
      "Epoch [243/300], Loss: 1.696063613012639\n",
      "Epoch [244/300], Loss: 1.545319561584754\n",
      "Epoch [245/300], Loss: 2.1842603200042303\n",
      "Epoch [246/300], Loss: 2.3048607610887095\n",
      "Epoch [247/300], Loss: 2.1696216521724576\n",
      "Epoch [248/300], Loss: 4.201715043063538\n",
      "Epoch [249/300], Loss: 4.4650235989126745\n",
      "Epoch [250/300], Loss: 4.768107031896917\n",
      "Epoch [251/300], Loss: 6.400779746095156\n",
      "Epoch [252/300], Loss: 6.94639760557957\n",
      "Epoch [253/300], Loss: 7.1359457727950835\n",
      "Epoch [254/300], Loss: 4.63032353308893\n",
      "Epoch [255/300], Loss: 4.220742915632538\n",
      "Epoch [256/300], Loss: 4.595926552873602\n",
      "Epoch [257/300], Loss: 3.163207651832686\n",
      "Epoch [258/300], Loss: 1.8759976257376956\n",
      "Epoch [259/300], Loss: 1.2326954828429333\n",
      "Epoch [260/300], Loss: 1.0683258557649251\n",
      "Epoch [261/300], Loss: 1.9408773958408339\n",
      "Epoch [262/300], Loss: 1.4274777992529804\n",
      "Epoch [263/300], Loss: 1.050900690017208\n",
      "Epoch [264/300], Loss: 1.0690975606716173\n",
      "Epoch [265/300], Loss: 0.8543358519330003\n",
      "Epoch [266/300], Loss: 0.6608771783415623\n",
      "Epoch [267/300], Loss: 0.6128739948096913\n",
      "Epoch [268/300], Loss: 0.5909950996873565\n",
      "Epoch [269/300], Loss: 0.5490093582786173\n",
      "Epoch [270/300], Loss: 0.6645502362932477\n",
      "Epoch [271/300], Loss: 0.5603314951268209\n",
      "Epoch [272/300], Loss: 0.638577683180708\n",
      "Epoch [273/300], Loss: 0.6724580795534195\n",
      "Epoch [274/300], Loss: 0.5907328359542354\n",
      "Epoch [275/300], Loss: 0.582693992122527\n",
      "Epoch [276/300], Loss: 0.690741090730588\n",
      "Epoch [277/300], Loss: 0.7556353593202231\n",
      "Epoch [278/300], Loss: 0.7522808978085145\n",
      "Epoch [279/300], Loss: 0.9450760546917191\n",
      "Epoch [280/300], Loss: 0.8775385151261009\n",
      "Epoch [281/300], Loss: 0.6963910309400426\n",
      "Epoch [282/300], Loss: 0.6859532874850084\n",
      "Epoch [283/300], Loss: 0.6086740636605821\n",
      "Epoch [284/300], Loss: 0.8472433518704181\n",
      "Epoch [285/300], Loss: 1.4800768909366449\n",
      "Epoch [286/300], Loss: 1.9556249737190212\n",
      "Epoch [287/300], Loss: 2.021526639911986\n",
      "Epoch [288/300], Loss: 1.7149032601563063\n",
      "Epoch [289/300], Loss: 1.7847212382725306\n",
      "Epoch [290/300], Loss: 2.533877957251764\n",
      "Epoch [291/300], Loss: 3.4807183357977096\n",
      "Epoch [292/300], Loss: 3.2323582293251145\n",
      "Epoch [293/300], Loss: 4.359914234706333\n",
      "Epoch [294/300], Loss: 3.7661861296622985\n",
      "Epoch [295/300], Loss: 3.655759196127615\n",
      "Epoch [296/300], Loss: 2.868504387991769\n",
      "Epoch [297/300], Loss: 2.0289130276798653\n",
      "Epoch [298/300], Loss: 2.3050969646823023\n",
      "Epoch [299/300], Loss: 2.251782178878784\n",
      "Epoch [300/300], Loss: 1.5119506444799187\n",
      "torch.Size([31, 28, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANT: \n",
    "# training code works only for \n",
    "used_embedding = \"naive\"\n",
    "# training and visualization code should work in both\n",
    "used_embedding = \"learned\"\n",
    "used_embedding = \"positional\"\n",
    "# used_embedding = \"naive\"\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = train(used_embedding=used_embedding)\n",
    "visualize_model_output(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn-hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
